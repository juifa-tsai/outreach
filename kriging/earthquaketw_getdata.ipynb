{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taiwan Earthquake Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as PD\n",
    "import geopandas as GPD\n",
    "import numpy as NP\n",
    "import wget as WGET\n",
    "import zipfile as ZIP\n",
    "from tqdm import tqdm as TQDM\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://opendata2.epa.gov.tw/SOIL00058/'\n",
    "datalist = ['地震報告詳細資料_1071214_052621',\n",
    "'地震報告詳細資料_1071216_053905',\n",
    "'地震報告詳細資料_1071225_125048',\n",
    "'地震報告詳細資料_1071229_220201',\n",
    "'地震報告詳細資料_1080104_022157',\n",
    "'地震報告詳細資料_1080104_071152',\n",
    "'地震報告詳細資料_1080108_063958',\n",
    "'地震報告詳細資料_1080108_202935',\n",
    "'地震報告詳細資料_1080122_112955',\n",
    "'地震報告詳細資料_1080130_135402',\n",
    "'地震報告詳細資料_1080130_233017',\n",
    "'地震報告詳細資料_1080131_063019',\n",
    "'地震報告詳細資料_1080205_195037',\n",
    "'地震報告詳細資料_1080208_012035',\n",
    "'地震報告詳細資料_1080213_024045',\n",
    "'地震報告詳細資料_1080215_222201',\n",
    "'地震報告詳細資料_1080217_184132',\n",
    "'地震報告詳細資料_1080308_110117',\n",
    "'地震報告詳細資料_1080312_121131',\n",
    "'地震報告詳細資料_1080313_043148',\n",
    "'地震報告詳細資料_1080313_125140',\n",
    "'地震報告詳細資料_1080314_053157',\n",
    "'地震報告詳細資料_1080316_091627',\n",
    "'地震報告詳細資料_1080317_211150',\n",
    "'地震報告詳細資料_1080319_123225',\n",
    "'地震報告詳細資料_1080403_121140',\n",
    "'地震報告詳細資料_1080404_101053',\n",
    "'地震報告詳細資料_1080404_211055',\n",
    "'地震報告詳細資料_1080406_055056',\n",
    "'地震報告詳細資料_1080408_151102',\n",
    "'地震報告詳細資料_1080409_234113',\n",
    "'地震報告詳細資料_1080410_044116',\n",
    "'地震報告詳細資料_1080410_072351',\n",
    "'地震報告詳細資料_1080415_233911',\n",
    "'地震報告詳細資料_1080418_132514',\n",
    "'地震報告詳細資料_1080418_134009',\n",
    "'地震報告詳細資料_1080501_113512',\n",
    "'地震報告詳細資料_1080502_191425',\n",
    "'地震報告詳細資料_1080503_061419',\n",
    "'地震報告詳細資料_1080513_171729',\n",
    "'地震報告詳細資料_1080522_100030',\n",
    "'地震報告詳細資料_1080523_144052',\n",
    "'地震報告詳細資料_1080531_001349',\n",
    "'地震報告詳細資料_1080604_181202',\n",
    "'地震報告詳細資料_1080606_035426',\n",
    "'地震報告詳細資料_1080630_005402',\n",
    "'地震報告詳細資料_1080802_222042',\n",
    "'地震報告詳細資料_1080803_064030',\n",
    "'地震報告詳細資料_1080806_094028',\n",
    "'地震報告詳細資料_1080806_094029',\n",
    "'地震報告詳細資料_1080808_060032',\n",
    "'地震報告詳細資料_1080808_072021',\n",
    "'地震報告詳細資料_1080816_060050',\n",
    "'地震報告詳細資料_1080817_232117',\n",
    "'地震報告詳細資料_1080817_000100',\n",
    "'地震報告詳細資料_1080818_122156',\n",
    "'地震報告詳細資料_1080831_160446',\n",
    "'地震報告詳細資料_1080903_091500',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:00<00:00, 21765.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Download data to local directory\n",
    "todir = './data'\n",
    "if not os.path.exists(todir):\n",
    "    os.makedirs(todir)\n",
    "bars = TQDM(datalist)\n",
    "for name in bars:\n",
    "    filename = os.path.join(todir, name)\n",
    "    # Download\n",
    "    if not os.path.exists(filename+'.zip'):\n",
    "        WGET.download(url+name+'.zip', out=filename+'.zip')\n",
    "    # Un-zip\n",
    "    if not os.path.exists(filename):\n",
    "        with ZIP.ZipFile(filename+'.zip', 'r') as zipfile:\n",
    "            zipfile.extractall(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reconstruct data to DataFrame from .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define column names\n",
    "data = {'event':[],\n",
    "        'datetime':[],\n",
    "        'lon':[],\n",
    "        'lat':[],\n",
    "        'depth':[],\n",
    "        'intensity':[],\n",
    "        'station_id':[],\n",
    "        'station_name':[],\n",
    "        'station_lon':[],\n",
    "        'station_lat':[],\n",
    "        'distance':[],\n",
    "        'az':[],\n",
    "        'pga_v':[],\n",
    "        'pga_ns':[],\n",
    "        'pga_ew':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:00<00:00, 501.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loop earthqauke events from each .txt\n",
    "# Each event contain many measurments from stations\n",
    "todir = './data'\n",
    "bars = TQDM(datalist)\n",
    "for event, name in enumerate(bars):\n",
    "    dirname = os.path.join(todir, name)\n",
    "    filename = None\n",
    "    # find .txt data\n",
    "    for path, dirs, files  in os.walk(dirname):\n",
    "        if path == dirname:\n",
    "            for f in files:\n",
    "                if f.find('E.txt') >= 0:\n",
    "                    filename = f\n",
    "                    break\n",
    "            break\n",
    "    # read .txt data and reconstruct to .csv\n",
    "    with open(os.path.join(dirname, filename), 'rb') as file:\n",
    "        contain = [l.decode('utf8', 'ignore') for l in file.readlines()]\n",
    "        datetime = None\n",
    "        lon = None\n",
    "        lat = None\n",
    "        depth = None\n",
    "        intensity = None\n",
    "        for line in contain:\n",
    "            line = line.strip('\\n').strip('\\r')\n",
    "            ## Event information\n",
    "            if line.find('Origin Time:') >= 0:\n",
    "                datetime = line.split('Origin Time:')[1].replace('/', '-')\n",
    "            if line.find('Lon:') >= 0:\n",
    "                lon = float(re.findall(\"\\d+\\.\\d+\", line)[0])\n",
    "            if line.find('Lat:') >= 0:\n",
    "                lat = float(re.findall(\"\\d+\\.\\d+\", line)[0])\n",
    "            if line.find('Depth:') >= 0:\n",
    "                depth = float(re.findall(\"\\d+\\.\\d+\", line)[0])\n",
    "            if line.find('Mag:') >= 0:\n",
    "                intensity = float(re.findall(\"\\d+\\.\\d+\", line)[0])\n",
    "            ## Station information\n",
    "            if line.find('Stacode') >= 0:\n",
    "                values = line.replace(' ', '').split(',')\n",
    "                station_id = None\n",
    "                station_name = None\n",
    "                station_lon = None\n",
    "                station_lat = None\n",
    "                distance = None\n",
    "                az = None\n",
    "                pga_v = None \n",
    "                pga_ns = None \n",
    "                pga_ew = None\n",
    "                for v in values:\n",
    "                    col = v.split('=')[0]\n",
    "                    val = v.split('=')[1]\n",
    "                    if col == 'Stacode':\n",
    "                        station_id = val\n",
    "                    if col == 'Staname':\n",
    "                        station_name = val\n",
    "                    if col == 'Stalon':\n",
    "                        station_lon = float(val)\n",
    "                    if col == 'Stalat':\n",
    "                        station_lat = float(val)\n",
    "                    if col == 'Dist':\n",
    "                        distance = float(val)\n",
    "                    if col == 'AZ':\n",
    "                        az = float(val)\n",
    "                    if col == 'PGA(V)':\n",
    "                        pga_v = float(val)\n",
    "                    if col == 'PGA(NS)':\n",
    "                        pga_ns = float(val)\n",
    "                    if col == 'PGA(EW)':\n",
    "                        pga_ew = float(val)\n",
    "                data['event'].append(event)\n",
    "                data['datetime'].append(datetime)\n",
    "                data['lon'].append(lon)\n",
    "                data['lat'].append(lat)\n",
    "                data['depth'].append(depth)\n",
    "                data['intensity'].append(intensity)\n",
    "                data['station_id'].append(station_id)\n",
    "                data['station_name'].append(station_name)\n",
    "                data['station_lon'].append(station_lon)\n",
    "                data['station_lat'].append(station_lat)\n",
    "                data['distance'].append(distance)\n",
    "                data['az'].append(az)\n",
    "                data['pga_v'].append(pga_v)\n",
    "                data['pga_ns'].append(pga_ns)\n",
    "                data['pga_ew'].append(pga_ew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event             int64\n",
      "datetime         object\n",
      "lon             float64\n",
      "lat             float64\n",
      "depth           float64\n",
      "intensity       float64\n",
      "station_id       object\n",
      "station_name     object\n",
      "station_lon     float64\n",
      "station_lat     float64\n",
      "distance        float64\n",
      "az              float64\n",
      "pga_v           float64\n",
      "pga_ns          float64\n",
      "pga_ew          float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>datetime</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>depth</th>\n",
       "      <th>intensity</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_lon</th>\n",
       "      <th>station_lat</th>\n",
       "      <th>distance</th>\n",
       "      <th>az</th>\n",
       "      <th>pga_v</th>\n",
       "      <th>pga_ns</th>\n",
       "      <th>pga_ew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-14 04:56:39</td>\n",
       "      <td>121.53</td>\n",
       "      <td>24.06</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>TWD</td>\n",
       "      <td>Xiulin</td>\n",
       "      <td>121.60</td>\n",
       "      <td>24.08</td>\n",
       "      <td>8.22</td>\n",
       "      <td>255.19</td>\n",
       "      <td>8.24</td>\n",
       "      <td>5.79</td>\n",
       "      <td>9.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-14 04:56:39</td>\n",
       "      <td>121.53</td>\n",
       "      <td>24.06</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ETM</td>\n",
       "      <td>Tongmen</td>\n",
       "      <td>121.49</td>\n",
       "      <td>23.97</td>\n",
       "      <td>11.26</td>\n",
       "      <td>17.81</td>\n",
       "      <td>27.06</td>\n",
       "      <td>53.78</td>\n",
       "      <td>37.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-14 04:56:39</td>\n",
       "      <td>121.53</td>\n",
       "      <td>24.06</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>HWA</td>\n",
       "      <td>HualienCity</td>\n",
       "      <td>121.61</td>\n",
       "      <td>23.98</td>\n",
       "      <td>13.09</td>\n",
       "      <td>317.56</td>\n",
       "      <td>15.05</td>\n",
       "      <td>14.58</td>\n",
       "      <td>23.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-14 04:56:39</td>\n",
       "      <td>121.53</td>\n",
       "      <td>24.06</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ETL</td>\n",
       "      <td>Taroko</td>\n",
       "      <td>121.62</td>\n",
       "      <td>24.16</td>\n",
       "      <td>14.44</td>\n",
       "      <td>222.69</td>\n",
       "      <td>5.94</td>\n",
       "      <td>19.33</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-14 04:56:39</td>\n",
       "      <td>121.53</td>\n",
       "      <td>24.06</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ETLH</td>\n",
       "      <td>Xibao</td>\n",
       "      <td>121.48</td>\n",
       "      <td>24.21</td>\n",
       "      <td>16.64</td>\n",
       "      <td>164.09</td>\n",
       "      <td>6.89</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event             datetime     lon    lat  depth  intensity station_id  \\\n",
       "0      0  2018-12-14 04:56:39  121.53  24.06   17.7        3.5        TWD   \n",
       "1      0  2018-12-14 04:56:39  121.53  24.06   17.7        3.5        ETM   \n",
       "2      0  2018-12-14 04:56:39  121.53  24.06   17.7        3.5        HWA   \n",
       "3      0  2018-12-14 04:56:39  121.53  24.06   17.7        3.5        ETL   \n",
       "4      0  2018-12-14 04:56:39  121.53  24.06   17.7        3.5       ETLH   \n",
       "\n",
       "  station_name  station_lon  station_lat  distance      az  pga_v  pga_ns  \\\n",
       "0       Xiulin       121.60        24.08      8.22  255.19   8.24    5.79   \n",
       "1      Tongmen       121.49        23.97     11.26   17.81  27.06   53.78   \n",
       "2  HualienCity       121.61        23.98     13.09  317.56  15.05   14.58   \n",
       "3       Taroko       121.62        24.16     14.44  222.69   5.94   19.33   \n",
       "4        Xibao       121.48        24.21     16.64  164.09   6.89    8.04   \n",
       "\n",
       "   pga_ew  \n",
       "0    9.97  \n",
       "1   37.68  \n",
       "2   23.59  \n",
       "3   15.33  \n",
       "4    8.54  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dict to DataFrame\n",
    "data = PD.DataFrame.from_dict(data)\n",
    "print(data.dtypes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic feature engineering for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform geometry projection function\n",
    "def transform( data, x_col, y_col, from_crs, to_crs ):\n",
    "    data_tmp = data.copy()\n",
    "    data_tmp['geom'] = data_tmp.apply(lambda x: Point(x[x_col], x[y_col]), axis=1)\n",
    "    geom = GPD.GeoDataFrame(data_tmp[['geom']], geometry='geom')\n",
    "    geom.crs = {'init':from_crs}\n",
    "    geom = geom.to_crs({'init':to_crs})\n",
    "    data_tmp[x_col] = geom['geom'].x\n",
    "    data_tmp[y_col] = geom['geom'].y\n",
    "    return data_tmp.drop('geom', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasform degree projection (epsg:4326) to meter projection of Taiwan region (epsg:3826)\n",
    "data = transform(data, 'lon', 'lat', from_crs='epsg:4326', to_crs='epsg:3826')\n",
    "data = transform(data, 'station_lon', 'station_lat', from_crs='epsg:4326', to_crs='epsg:3826')\n",
    "# distance from station to event\n",
    "data['d'] = NP.sqrt((data['lon'] - data['station_lon'])**2 + (data['lat'] - data['station_lat'])**2)\n",
    "# maximum pga\n",
    "data['pga_max'] = NP.maximum(data['pga_v'].values, data['pga_ns'].values, data['pga_ew'].values)\n",
    "# total pga\n",
    "data['pga'] = NP.sqrt(data['pga_v']**2 + data['pga_ns']**2 + data['pga_ew']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./data/earthquaketw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>datetime</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>depth</th>\n",
       "      <th>intensity</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_lon</th>\n",
       "      <th>station_lat</th>\n",
       "      <th>distance</th>\n",
       "      <th>az</th>\n",
       "      <th>pga_v</th>\n",
       "      <th>pga_ns</th>\n",
       "      <th>pga_ew</th>\n",
       "      <th>d</th>\n",
       "      <th>pga_max</th>\n",
       "      <th>pga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-14 04:56:39</td>\n",
       "      <td>303898.534518</td>\n",
       "      <td>2.661770e+06</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>TWD</td>\n",
       "      <td>Xiulin</td>\n",
       "      <td>311007.912765</td>\n",
       "      <td>2.664013e+06</td>\n",
       "      <td>8.22</td>\n",
       "      <td>255.19</td>\n",
       "      <td>8.24</td>\n",
       "      <td>5.79</td>\n",
       "      <td>8.24</td>\n",
       "      <td>7455.018061</td>\n",
       "      <td>8.24</td>\n",
       "      <td>13.012275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-14 04:56:39</td>\n",
       "      <td>303898.534518</td>\n",
       "      <td>2.661770e+06</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ETM</td>\n",
       "      <td>Tongmen</td>\n",
       "      <td>299865.343998</td>\n",
       "      <td>2.651787e+06</td>\n",
       "      <td>11.26</td>\n",
       "      <td>17.81</td>\n",
       "      <td>27.06</td>\n",
       "      <td>53.78</td>\n",
       "      <td>53.78</td>\n",
       "      <td>10766.259718</td>\n",
       "      <td>53.78</td>\n",
       "      <td>80.726826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-14 04:56:39</td>\n",
       "      <td>303898.534518</td>\n",
       "      <td>2.661770e+06</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>HWA</td>\n",
       "      <td>HualienCity</td>\n",
       "      <td>312072.754264</td>\n",
       "      <td>2.652942e+06</td>\n",
       "      <td>13.09</td>\n",
       "      <td>317.56</td>\n",
       "      <td>15.05</td>\n",
       "      <td>14.58</td>\n",
       "      <td>15.05</td>\n",
       "      <td>12030.634070</td>\n",
       "      <td>15.05</td>\n",
       "      <td>25.798864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-14 04:56:39</td>\n",
       "      <td>303898.534518</td>\n",
       "      <td>2.661770e+06</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ETL</td>\n",
       "      <td>Taroko</td>\n",
       "      <td>313002.380630</td>\n",
       "      <td>2.672882e+06</td>\n",
       "      <td>14.44</td>\n",
       "      <td>222.69</td>\n",
       "      <td>5.94</td>\n",
       "      <td>19.33</td>\n",
       "      <td>19.33</td>\n",
       "      <td>14365.702485</td>\n",
       "      <td>19.33</td>\n",
       "      <td>27.974656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-14 04:56:39</td>\n",
       "      <td>303898.534518</td>\n",
       "      <td>2.661770e+06</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ETLH</td>\n",
       "      <td>Xibao</td>\n",
       "      <td>298756.774779</td>\n",
       "      <td>2.678364e+06</td>\n",
       "      <td>16.64</td>\n",
       "      <td>164.09</td>\n",
       "      <td>6.89</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.04</td>\n",
       "      <td>17372.811019</td>\n",
       "      <td>8.04</td>\n",
       "      <td>13.294935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event             datetime            lon           lat  depth  intensity  \\\n",
       "0      0  2018-12-14 04:56:39  303898.534518  2.661770e+06   17.7        3.5   \n",
       "1      0  2018-12-14 04:56:39  303898.534518  2.661770e+06   17.7        3.5   \n",
       "2      0  2018-12-14 04:56:39  303898.534518  2.661770e+06   17.7        3.5   \n",
       "3      0  2018-12-14 04:56:39  303898.534518  2.661770e+06   17.7        3.5   \n",
       "4      0  2018-12-14 04:56:39  303898.534518  2.661770e+06   17.7        3.5   \n",
       "\n",
       "  station_id station_name    station_lon   station_lat  distance      az  \\\n",
       "0        TWD       Xiulin  311007.912765  2.664013e+06      8.22  255.19   \n",
       "1        ETM      Tongmen  299865.343998  2.651787e+06     11.26   17.81   \n",
       "2        HWA  HualienCity  312072.754264  2.652942e+06     13.09  317.56   \n",
       "3        ETL       Taroko  313002.380630  2.672882e+06     14.44  222.69   \n",
       "4       ETLH        Xibao  298756.774779  2.678364e+06     16.64  164.09   \n",
       "\n",
       "   pga_v  pga_ns  pga_ew             d  pga_max        pga  \n",
       "0   8.24    5.79    8.24   7455.018061     8.24  13.012275  \n",
       "1  27.06   53.78   53.78  10766.259718    53.78  80.726826  \n",
       "2  15.05   14.58   15.05  12030.634070    15.05  25.798864  \n",
       "3   5.94   19.33   19.33  14365.702485    19.33  27.974656  \n",
       "4   6.89    8.04    8.04  17372.811019     8.04  13.294935  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPLE_NotSupported in Normalized/laundered field name: 'station_lon' to 'station_lo'\n",
      "CPLE_NotSupported in Normalized/laundered field name: 'station_lat' to 'station_la'\n"
     ]
    }
   ],
   "source": [
    "# Save station location to shapefile\n",
    "stations = data.groupby('station_id')[['station_lon', 'station_lat']].max().reset_index()\n",
    "stations['geom'] = stations[['station_lon', 'station_lat']].apply(lambda x: Point(x), axis=1)\n",
    "stations = GPD.GeoDataFrame(stations, geometry='geom')\n",
    "stations.crs={'init' :'epsg:3826'}\n",
    "stations.to_file('./data/earthquaketw_stations.shp', driver='ESRI Shapefile', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save event location to shapefile\n",
    "events = data.groupby('datetime')[['event','lon','lat','depth','intensity']].max()\n",
    "events['geom'] = events[['lon', 'lat']].apply(lambda x: Point(x), axis=1)\n",
    "events = GPD.GeoDataFrame(events, geometry='geom')\n",
    "events.crs={'init' :'epsg:3826'}\n",
    "events.to_file('./data/earthquaketw_events.shp', driver='ESRI Shapefile', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = GPD.read_file('meuse_example_data/meuse.shp')\n",
    "gdf.crs = {'init':'epsg:28992'}\n",
    "gdf.head()\n",
    "gdf['x'] = gdf['geometry'].apply(lambda x: x.x)\n",
    "gdf['y'] = gdf['geometry'].apply(lambda x: x.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.to_crs({'init':'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('./data/muese.shp', driver='ESRI Shapefile', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
